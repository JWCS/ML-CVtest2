11/03/016 
PreSpring break; v0.1 completed. Next step fix edge problems with expansion. Effectively, have a gradient function and threshold function in play, as well as a flawed edge tracer: edge thinning & edge following prof said, finish in spring break;

14/03/2016 Decided that the changes to the code would change 100% of it. Instead of preserving old files that I would usurp with newer and better versions, I created a new repository, CVTrial2, and will make that public/github. Effectively little or none of the code will be kept, unless I find a use to copy or paste something. 
14/03/2016 Ok, I think I figured out the order now (for this attempt). First, filter, 3d. Then use a gradient operator (I first used robertson's apparently, now I'm trying sobel's), 3d. I want to take the gradient in 3d so that it will respond better to changes in color, not so in changes in intensity. From Gradient Operator (3d), I convert it into an intensity 2d matrix, with threshold. Then, if I understood this right, I expand the edges, and set up a line following algorithm. I think if I use sobel's I can turn the 2 matricies of 3d color (delX dir, delY dir), into 2 matricies of 2d data: an intensity/magnitude 2d matrix and a directional 2d matrix. Using this second matrix, I think I can write line following code. I will try to begin that on Tues. 
14/03/2016 Finished EdgeOperator, however I'm not sure about the 255/something scale, or that I should use the intensity fractions for rgb2gray for the magnitude of change for RGB mats to ImMag. Also, it was kinda generically written for multiple types of edge operators, but I'm just planning on using sobels. Threshold will need tweaking. Implementing expansion will be interesting, magnitude or logical? ImDir is in range of [-pi, pi]. Some areas need expansion & line thinning: if we could combine the two with thresholding using ImDir, maybe this could be clean. 
15/03/16 Fixed edge operator to be mean of RGB, it appears better. I haven't fixed xy notation to mn notation, as I'll need for ImDir... Almost finished Expansion, just bug fixing. That notation tho, the real trick here; 
16/03/16 I am not pleased with matlab's notation. What I could seemingly do in one place to lessen computation I appear to be unable to do here. Note: ask someone knowledge able if there is a way to skip past a performance in an array function opperating like a for loop, ex A(:,:) = f(B(:,:)); if B(m,n) = 0 or the like, since 7/8ths of the expansion matrix is zeros and does not need the computation performed on those elements. In anycase, the code for expansion in 8-connectivity works, and quickly(ish) too: around .8 to 1.2 seconds, not sure why the range. Currently main takes around 4.5 seconds. Commiting it now as finished 8-connectivity expansion. Also, I am not sure about rgb2grey intensity, but I like the more absolute change better, so I'm deleting all of that, it works without and should be unnecessary. Lastly, I'm fixing edge operator to actually point in direction of positive m and n, instead of my sudo xy directions. By the time this is commited, there is no obvious problems with that, except I haven't used ImDir yet. 
17/03/16 Begun DirExpansion. Effectively the same as Expansion, most of the code is cp. The difference is a logical mat .* to the new___Vals, where the mat is of points where the initial mat is pointing to. The logical mat I think is best woven into border(:,:). 
18/03/16 Finished DirExpansion. It isn't as tight as it could be, featuring for loops, but it doen't take too long (~2sec per) and works. Wrote an isolated point removal thing, very simple. I think I next need to thin the lines, which might be tedious. Even moreso, now I look, is figuring out the line following algorithm. The DirExpansion works well in the areas it was designed to work in, the areas with incomplete lines, but it covers the area with splotches of pixel groups with blotches of non pixel groups- need to pre-filter out these things. 
Almost finished with median filter- It improves the image a ton! Well, that and I switched also to experiment with median filter zone size 5 and sobel5 edge operator. Thresholds of somewhere around [100,130) seem to make the image quite more clear. Will try zone size 7+, just to see. Run time about .5 min
19/03/16 Cleaning up the code, the parameters, to optimalize the image for edge thinning. It needs to be done, but it looks tricky. Reading up on it while code compiles. Apparently, median filter of 7+ on a side leads to memory problems... and I have a ton of ram. So, it's confined to 3||5. I'm running with sobel5 and 5x5 median filter zone. I've tried multiple filters, but I'm not sure if it does anything significant, or at least anything I know how to take advantage of. Running with one instance. Threshold, under circumstances, is too low at 80 (no broken edges) and too high? at 120 (broken edges). Attempting to implement an algorithm to find an optimal (maybe) threshold, at least something better than mere guessing. Officially starting that edge thinning. 
26/03/16 It's been a busy week. Still learning. Have made a few things, Median Filter, but have tried hard on thinning alg, but sketchy process. I think I'm 'close', but the code has something wrong. I've read up online, & I'm better equipt to code this. I tried to use, for thinning, stentiford alg, but I didn't understand connectivity. I tried to use zhang-suen, but something implementation was wrong. So, going to the basics, a point is removed if it's there, it has >6 or <2 neighbors, and has connectivity =1 (I understand that, finally). 
1/4/16 I have been trying to thin based off of these rules: the points are taken into consideration 1 at a time, it is a point, it has between 2 and 6 neighbors, and it does not disconnect the remaining others. I thought I had it, but I accidentally was considering them all at once, which broke connectivity. And there were small bugs in the code, but learning the invalubility of im2col & reshape helped. Yet... I have finally gotten thinning to work! However, it is very slow, projected time is 2.7 hrs just for this... But it works!
14/5/2016 Semester ended. I've briefly been looking at converting the lagging part of the code to C. I've optimized it, but this part I can not avoid. There may be a different methodology that is faster, but I need to see what the time difference is when converted into C. Also, it's just good for me. I'm getting close, and now I'll have the time to finish. 
21/5/2016 Converted the code in the problematic portion of the thinning code to mex/C. Finally got it to the point of which it should output the padded image, aka the background should all work before the tricky computation begins. However, after debugging it, everytime I ran the program on a test 16x16 piece I've been using, Matlab entirely crashes. After trying to no avail, I've decided that I've spent enough time trying to do this, and I am trying it in matlab again, this time with more experience and with Zhang Wang algorithm, which utilizes a 4x4 local matrix. Once again running into connectivity errors in code, but expected that. There is a problem of deleting a point and the adjacent point, of which one of the two needed to be removed, but both could, and then both were. Since Matlab just passes through the entire matrix, it doesn't perform element to element looping unless I use for loops or a limiter within the overarching loop to prevent that. Also cleaned up some of the functions/classes. I had somethings that I thought would help me, but it can't be shown they actually help the processing of the image, such as removing isolated points and the threshold tuner. Albiet still in recycling bin. 
22/5/2016 Finished making the ZhangWangThin function. I tried it twice on the ImMag matrix. First run, after finding all available points that meet the conditions, as per the style of matlab it deleted all of them immediately. This took ~34 seconds. It produced, however, many disconnections of roughly one pixel thick, an easy remedy perhaps. I added an input boolean variable, that if true, would have it then, with the pixels to delete, iteratively go through them and remove all that were neighbors. Thus connectivity is guarenteed to be preserved. This took ~130 seconds. It produced, however, many spurs, short shoot-offs of roughly a few pixels, plus some zig-zagging. I think a combination of the two methods plus some expansion should solve the problems and finsh producing an image to acquire lines from. The bulk of this final finishing work is shifting back to the main class. 
24/5/2016 I am close to beginning the line following algs. I am getting caught up in two things, the noise and the quality of expansion. First, is that my hand is not the only object in the picture: there is also my key and card, and some of my keyboard keys (as well as just some random points of noise). I'm not sure how I can accurately get the data for just my hand with those there. I could most likely get lines that match the hand, but then there will be other lines not belonging to it, template? Also, some of the lines will be disconnected. I either lower the threshold, more noise, but more connectivity, or I enhance my expansion algorithms to make bigger and better connections (or of course both). This leads me to a second point. I don't think I will ever need the whole hand, just enough defining points to create utilizable points. Boundaries of fingertips, roughly fingertip pads, center/ corners of the palm, most external boundaries of the hand (outer pinky, outer pointer, thumb, palm/wrist boundaries). Even if I have disjointed lines that together compose most of the hand, if, if, if, I can isolate them from the noise, identify them as being part of this object, I should be able to call it good. Also, it has been a while since I wrote my expansion and directional expansion algs, and I originally made them to maintain magnitude data, upon image analysis I have found the data useless and a waste of computational time. Also, the DirExpansion is actually quite similar to my end expansion. The later is better as it operates on the ends, neighbor no ==1, of lines. I might just remove/sudodelete DirExpansion and incorporate the directional data into a clause, given the ImDir data. 
25/05/2016 Must later create spur deletion function. Need to later investigate sparse arrays. Need to look at profile and clean up inefficiencies in ZhangWangThin. I am reworking DirExpansion (old code moved to OldDir... function just in case) to act either on just ends of lines or both ends and isolated points, and based on the direction matrix follow from the point in a chain until it meets another valid point. Have now discovered the potential problem of loops, which have occured. IDK about them. 
26/05/2016 Comments/Thought guide on DirExpansion
%Feed index of valid start points into ImDir to acquire dirs per index
%value. The dirs matrix plus the raw index matrix plus M,N return a new
%they already exist. The remaining points plus the original points get
%moved to a new matrix. Evaluating the new ends (no iso points left), get
%new ends from those ends till it hits something. Keep evolving it. Need an
%algorithim implementing this to remove iso points. Keep a matrix of points
%to check and full evolved matrix.
DirExpansion seems to work on some parts of the pic. I tested it on a section that was effectively a flat line, that worked well. Other places, diagnals I know, something is buggy. There haven't been any chains going ad infinitum, as I expected. I wonder why. It is too late today for more work. 
27/05/2016 I haven't been working on this continually, but I want to finish it. I have been confused on how to best expand/thin/connect lines/isopoints in the image to make the line acquisition the easiest. I profiled ZhangWangThin, optimization for it is not effectively feasible/cost effective. The key places that delay, the only parts worth optimizing are 1) in the image to cols by sliding 4x4, I included the raw code for it, optimized to exactly barebones what I need, but the critical line in there is the "out= Mag( reshape( bsxfun( ..." trio of functions, and I don't think I can optimize those, 2) for loops for itterative section, much time in if statements, shouldn't matter for the choice application. All alt ways to do the interior of loops took longer, noted in class. This is my working strategy for expanding and thinning. 
1) Rapidly skeletonize with nonitterative ZhangWangThin, which should leave breaks in chains of a pixel or two. 
2) Repeat for a few itterations of 8-connectivity expansion followed by itterative ZhangWang. This should take care of 2 px gaps, but for each additional 2 desired, expansion must be executed an additional time before thinning, which creates spurs. Also, realized, spurs on this level are merely just ends of lines; at a higher level they are the ends of short lines attached to a larger established line. At a low level, I can only recede ends to eliminate spurs. I would have to get into line definitions in order to more choicely eliminate. 
Just doing 1&2, with 5 itterations of 2, where the number of itterations of expansion is also equal to the current itteration number, is over 10 min. with profiler. I ran it like so w/o profiler, took 540 seconds. Most of that was ZhangWangThin itterative, barely any (except the first round for some reason) was expansion, each call of that was >1 sec. The final image, I saved the mat file as spuriousFullyConnected..., is actually fully connected. Five rounds of expansion plus itterative thinning managed to connect everything, albiet produced a ton of spurs. The spurs are so bad they almost destroy the image; however, this discovery means something new now. I have two options, one I was planning before I realized this (quicker too I think) and the other is to proceed with this image, keep assumptionn of utter connectedness (I think it valid). 
3A) Lessen itterations to 2 or 3, find out which is better at minimizing spurs and time while acquiring connections. 
4A) Using a combo of DirExpansion (uses ImDir to find connections/points) and EndConnections (also uses ends, but makes no assumptions on direction, assumes proximity) finish connecting up lines. 
5A) Thin last time and remove spurs and isolated points. Everything now should be simply connected, except for loops of lines. 
6A) Acquire lines. If there is a junction, send a tracer down each, one will run into another, thus becoming a 'spur' somehow. 
3B) Using the full 5 itterations matrix, kill spurs and iso points harshly. Remove all points with neighbors of one or none many times. 
4B) Acquire lines. 
A requires more steps, but should be faster than B because B is more blunt and has to utilize the itterative thinning repeatedly on thick lines. 
I will begin by trying B, since I have already computed the starting matrix, and it should go smoothly. A would be quicker tho, personally want to develop down that line but I ought to just finish this. 
30/05/2016
Using a combination of spur/end/isopoint removing in loops with thinning, the image reduces to loops, endpoints of loops, and the huge overarching image of the hand. The loops are throwing me a bit, as false data caused by the expansion. I must refine that part, I do not like the sheer quantity and size of the loops. 
I stumbled onto some optimization strategies. When I was originally optimizing itterative ZhangWangThin, if statements to assign values is much more efficient than including the boolean evaluation operation in the assignment, eg toDelete( m + 1 + n*M ) = toDelete(...) && ~toDelete(m,n); However, using one for loop, running through the index rather than m,n is much more efficient. I reduced the 'optimized' 2 loop 3 if statement code to 1 loop 1 if statement, and that cut the time from 150sec to 50sec. With this, I am much more confident in putting in a bit more work into the expansion part, albeit I must finish. 
Working straight on line part. I have an idea. I'm stopping thinking about the itching expansion thing-ama-bobber because as I've been looking into how to do this line acquisition part, I think I have a way to make loops irrelevant. 1) Get simple lines, edges, lines that lie inbetween a critical point: end or split (3 connections). 2) Get critical points. 3) Associate edges with pairs of critical points: crit1, crit2, line4 (length/weight X). 3.5) If a line has both ends at the same end point, a loop, delete line, label split as end. 4) Run through splits. Ok: crit0, crit1, line1; find crit0->line2->crit2. 5) If crit2 is crit1, delete the longer line of 1 and 2, mark crit1/2 as not crit points, make new line crit-1, crit3, line(lastLine+1) (weight (line1)+line(2)+2). 6) If crit2 is not crit1, using the table of crit points make a list of trails between the points. 7) Make a new line composed of the intermediatory lines with the crit1/2 end points, keep/add to list the shortest line. This should converge to lines with ends, without loops, as short as possible. There might be, however, a problem if there is a quadrilateral. Will work on that then. I would also assume to delete lines with ends that are below a given threshold. 
02/06/2016 Can't remember why I went day/month/year. 1) ZhangWangThin didn't catch all the points to be deleted, by it's own rules. No clue why. bwmorph matlab function catches the 40 odd ones, so I'll have to take a look and edit Zhang. I think I've been not quite going about the lines right. Instead of sorting out options, I had forgotten to make use of the directional matrix I generated, ImDir. I've kept the lines in a matrix, and each row corresponds to a row in LineIDs, which has the critical points (end or split) at each end of each line. What I need to do, is after a line has been added & critical ppt found, I need to test that one points to the other. And same with the last point. If they don't, as many spur or falsely generated loops do, it gets deleted from the NeighborNo matrix, which is where the most raw data is kept. Then the info from that is funneled back into Lines & lineIDs anew. In the case of still splits... IDK yet, that ought to get rid of most. Problem as mentioned with Zhang Wang. I need to finish this asap. As soon as I get a list of lines and convert it to a matrix or whatever, an image at least, I'm emailing. Even with fam, this is too long. And I've prob shot myself in the foot too many times. 
04/06/2016 This needs to end. Found bug with Zhang Wang alg: It's actually a 4-connectivity alg I think. To convert it to 8-connectivity, the connectivity alg A(p2)==1 needs to be changed (but in the paper that wasn't mentioned, so I originally wrote it 8 conn), and the 4th and 5th requirements are changed as follows:
R4: p2*p4*p8=0 or p11=1 -> ... OR (p11 or p10 or p12)=1;
R5: p2*p4*p6=0 or p15=1 -> ... OR (p14 or p15 or p16)=1;
It works better than the bwmorph thin at getting all points. I double checked most. Continuing with line. For time purposes, almost no work was done yesterday. 
7/6/16 I'm trying several ways to get the points. I have a large section of commented out code that ought to be close to working well, but I don't know why not. Trying another method. This ought to be good. 
16th June 2016. It has been a while since I worked on it- but I wrote another method, that ended up about the same as the first. The first assumed that with Imdir, the ends would point to the rough area where the next proper line should be, not a false one. The second made fewer assumptions about the validity of ImDir, but deleted all of the lines that weren't the closest to the ImDir angle +-180 degrees. Both methods deleted too many. Then I discovered an invalid assumption I made. 
Assumption: at each junction, each line leaving it came from the same critical point, a point with more than 2 neighbors. This was sometimes valid, but there were also junctions of these critical splits. Effectively, there was a lack of lines with 0 points inbetween these splits. Adding each possibility of neighboring splits as a line could fix one/both of those, once their code is fixed for it. 
The lack of progress on those made me think of using region processing for getting the proper lines. For a hand, there are 5 quasi-local maxes at the fingertips, 4 quasi-local mins inbetween, and a roughly sinusoidal shape- this could definitely be used to find it, but this was due... don't want to think about that. 
19th June 2016. I wanted to email prof on Friday, certain that this was just about done. Well, today I was positive it was done, but then it kept throwing strange errors at me. I hunted and hunted, but as strangely as they appeared they disappeared. I'm not sure what caused them, but they resulted in generating matrices that used up 9.6 GB of my ram, max alloted for matlab. All the code is working much better, I like it all much better, and if I didn't restrain myself I would keep on filtering the image until only the desired hand remained. Albeit, for the time spent, improving the expansion functions that undoubtedly contributed to the problems would be a higher priority. But the highest is to get this darn thing in! I know not the desired format he wants it in, but I'll give him the best that comes out. I have the two process, one that looks for the point in the direction of and behind each end of a line and a split, and if it matches up with a line either way (split points to line or line points to split), it keeps both lines. The other process, at each split, finds the two (or 3 in case of tie) points closest in direction with the direction point there, and keeps them. All points that seem to align have their lines kept. Except, if the line only has 1 connection rooting for it. One was the magic number to filter out weak lines and not too big of a requirement to delete real lines. I'm trying right now, now that they work, is trying them out one after another: perform same opp twice, A then B, or B then A. I'll just record the result of that, put the best looking one in main, collect samples of the image at various stages, and push it out. 
The results are that the first process destroys lines, and won't work at all. Testing optimal itterations of second process work. I found an odd thing, which I'm not sure if it's specific to this image, or generally, but setting the runs of process2 to run twice, significantly reduces the number of lines. Over half of the remaining lines (oh, and running multiple times did seem to remove some, negligibly few for runtime, loops) were those there to record the junctions. In the final printout, those will be removed as they will already been added to their proper lines. 
20 June 2016. I can't think of anything more to do on this that is actually worth doing except final cleanup. I've learned much during this project, and it would be too much to go back & rewrite everything (but ZhangWangThin is by far the best & most edited/optimized piece). I'll collect final examples of various stages, throw it and the main class in a readme, and throw in some explaination in the read me. I might run the program with a few sample pictures of hands, just to test, but that I might have overfit the program to the image, which I don't want to fix at this time. If prof reads this, thanks for the very interesting project- I feel like I have a very strong grasp now of Matlab, even though at the beginning I had only barely heard of it. The parallel programing structure is interesting, but not so easily convertable to, say, C/Java. Also, a critical efficiency improvement I did not implement was sparse matrices. I was not familiar with that at the beginning, and some of the code might not work when converted to sparse, causing me to rewrite and delay the project. 
21and22 June 2016. So, I tried, just for some semblence of validity, even though I have to manually pick the threshold for this to work, running other images through the program. In sum, in not as nice pictures, the final bsxfun operations in the toKeepInd s maxed out my 80% of 12 GB memory. So I added to main a loop and try/catch so that if memory maxes, and I'm too lazy & indiferent about these pictures, it will rerun all of main with a higher threshold. Emailing prof today. 

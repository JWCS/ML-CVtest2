11/03/016 
PreSpring break; v0.1 completed. Next step fix edge problems with expansion. Effectively, have a gradient function and threshold function in play, as well as a flawed edge tracer: edge thinning & edge following prof said, finish in spring break;

14/03/2016 Decided that the changes to the code would change 100% of it. Instead of preserving old files that I would usurp with newer and better versions, I created a new repository, CVTrial2, and will make that public/github. Effectively little or none of the code will be kept, unless I find a use to copy or paste something. 
14/03/2016 Ok, I think I figured out the order now (for this attempt). First, filter, 3d. Then use a gradient operator (I first used robertson's apparently, now I'm trying sobel's), 3d. I want to take the gradient in 3d so that it will respond better to changes in color, not so in changes in intensity. From Gradient Operator (3d), I convert it into an intensity 2d matrix, with threshold. Then, if I understood this right, I expand the edges, and set up a line following algorithm. I think if I use sobel's I can turn the 2 matricies of 3d color (delX dir, delY dir), into 2 matricies of 2d data: an intensity/magnitude 2d matrix and a directional 2d matrix. Using this second matrix, I think I can write line following code. I will try to begin that on Tues. 
14/03/2016 Finished EdgeOperator, however I'm not sure about the 255/something scale, or that I should use the intensity fractions for rgb2gray for the magnitude of change for RGB mats to ImMag. Also, it was kinda generically written for multiple types of edge operators, but I'm just planning on using sobels. Threshold will need tweaking. Implementing expansion will be interesting, magnitude or logical? ImDir is in range of [-pi, pi]. Some areas need expansion & line thinning: if we could combine the two with thresholding using ImDir, maybe this could be clean. 
15/03/16 Fixed edge operator to be mean of RGB, it appears better. I haven't fixed xy notation to mn notation, as I'll need for ImDir... Almost finished Expansion, just bug fixing. That notation tho, the real trick here; 
16/03/16 I am not pleased with matlab's notation. What I could seemingly do in one place to lessen computation I appear to be unable to do here. Note: ask someone knowledge able if there is a way to skip past a performance in an array function opperating like a for loop, ex A(:,:) = f(B(:,:)); if B(m,n) = 0 or the like, since 7/8ths of the expansion matrix is zeros and does not need the computation performed on those elements. In anycase, the code for expansion in 8-connectivity works, and quickly(ish) too: around .8 to 1.2 seconds, not sure why the range. Currently main takes around 4.5 seconds. Commiting it now as finished 8-connectivity expansion. Also, I am not sure about rgb2grey intensity, but I like the more absolute change better, so I'm deleting all of that, it works without and should be unnecessary. Lastly, I'm fixing edge operator to actually point in direction of positive m and n, instead of my sudo xy directions. By the time this is commited, there is no obvious problems with that, except I haven't used ImDir yet. 
17/03/16 Begun DirExpansion. Effectively the same as Expansion, most of the code is cp. The difference is a logical mat .* to the new___Vals, where the mat is of points where the initial mat is pointing to. The logical mat I think is best woven into border(:,:). 
18/03/16 Finished DirExpansion. It isn't as tight as it could be, featuring for loops, but it doen't take too long (~2sec per) and works. Wrote an isolated point removal thing, very simple. I think I next need to thin the lines, which might be tedious. Even moreso, now I look, is figuring out the line following algorithm. The DirExpansion works well in the areas it was designed to work in, the areas with incomplete lines, but it covers the area with splotches of pixel groups with blotches of non pixel groups- need to pre-filter out these things. 
Almost finished with median filter- It improves the image a ton! Well, that and I switched also to experiment with median filter zone size 5 and sobel5 edge operator. Thresholds of somewhere around [100,130) seem to make the image quite more clear. Will try zone size 7+, just to see. Run time about .5 min
19/03/16 Cleaning up the code, the parameters, to optimalize the image for edge thinning. It needs to be done, but it looks tricky. Reading up on it while code compiles. Apparently, median filter of 7+ on a side leads to memory problems... and I have a ton of ram. So, it's confined to 3||5. I'm running with sobel5 and 5x5 median filter zone. I've tried multiple filters, but I'm not sure if it does anything significant, or at least anything I know how to take advantage of. Running with one instance. Threshold, under circumstances, is too low at 80 (no broken edges) and too high? at 120 (broken edges). Attempting to implement an algorithm to find an optimal (maybe) threshold, at least something better than mere guessing. Officially starting that edge thinning. 
26/03/16 It's been a busy week. Still learning. Have made a few things, Median Filter, but have tried hard on thinning alg, but sketchy process. I think I'm 'close', but the code has something wrong. I've read up online, & I'm better equipt to code this. I tried to use, for thinning, stentiford alg, but I didn't understand connectivity. I tried to use zhang-suen, but something implementation was wrong. So, going to the basics, a point is removed if it's there, it has >6 or <2 neighbors, and has connectivity =1 (I understand that, finally). 
1/4/16 I have been trying to thin based off of these rules: the points are taken into consideration 1 at a time, it is a point, it has between 2 and 6 neighbors, and it does not disconnect the remaining others. I thought I had it, but I accidentally was considering them all at once, which broke connectivity. And there were small bugs in the code, but learning the invalubility of im2col & reshape helped. Yet... I have finally gotten thinning to work! However, it is very slow, projected time is 2.7 hrs just for this... But it works!
14/4/2016 Semester ended. I've briefly been looking at converting the lagging part of the code to C. I've optimized it, but this part I can not avoid. There may be a different methodology that is faster, but I need to see what the time difference is when converted into C. Also, it's just good for me. I'm getting close, and now I'll have the time to finish. 
21/5/2016 Converted the code in the problematic portion of the thinning code to mex/C. Finally got it to the point of which it should output the padded image, aka the background should all work before the tricky computation begins. However, after debugging it, everytime I ran the program on a test 16x16 piece I've been using, Matlab entirely crashes. After trying to no avail, I've decided that I've spent enough time trying to do this, and I am trying it in matlab again, this time with more experience and with Zhang Wang algorithm, which utilizes a 4x4 local matrix. Once again running into connectivity errors in code, but expected that. There is a problem of deleting a point and the adjacent point, of which one of the two needed to be removed, but both could, and then both were. Since Matlab just passes through the entire matrix, it doesn't perform element to element looping unless I use for loops or a limiter within the overarching loop to prevent that. Also cleaned up some of the functions/classes. I had somethings that I thought would help me, but it can't be shown they actually help the processing of the image, such as removing isolated points and the threshold tuner. Albiet still in recycling bin. 
22/5/2016 Finished making the ZhangWangThin function. I tried it twice on the ImMag matrix. First run, after finding all available points that meet the conditions, as per the style of matlab it deleted all of them immediately. This took ~34 seconds. It produced, however, many disconnections of roughly one pixel thick, an easy remedy perhaps. I added an input boolean variable, that if true, would have it then, with the pixels to delete, iteratively go through them and remove all that were neighbors. Thus connectivity is guarenteed to be preserved. This took ~130 seconds. It produced, however, many spurs, short shoot-offs of roughly a few pixels, plus some zig-zagging. I think a combination of the two methods plus some expansion should solve the problems and finsh producing an image to acquire lines from. The bulk of this final finishing work is shifting back to the main class. 
24/5/2016 I am close to beginning the line following algs. I am getting caught up in two things, the noise and the quality of expansion. First, is that my hand is not the only object in the picture: there is also my key and card, and some of my keyboard keys (as well as just some random points of noise). I'm not sure how I can accurately get the data for just my hand with those there. I could most likely get lines that match the hand, but then there will be other lines not belonging to it, template? Also, some of the lines will be disconnected. I either lower the threshold, more noise, but more connectivity, or I enhance my expansion algorithms to make bigger and better connections (or of course both). This leads me to a second point. I don't think I will ever need the whole hand, just enough defining points to create utilizable points. Boundaries of fingertips, roughly fingertip pads, center/ corners of the palm, most external boundaries of the hand (outer pinky, outer pointer, thumb, palm/wrist boundaries). Even if I have disjointed lines that together compose most of the hand, if, if, if, I can isolate them from the noise, identify them as being part of this object, I should be able to call it good. Also, it has been a while since I wrote my expansion and directional expansion algs, and I originally made them to maintain magnitude data, upon image analysis I have found the data useless and a waste of computational time. Also, the DirExpansion is actually quite similar to my end expansion. The later is better as it operates on the ends, neighbor no ==1, of lines. I might just remove/sudodelete DirExpansion and incorporate the directional data into a clause, given the ImDir data. 
25/05/2016 Must later create spur deletion function. Need to later investigate sparse arrays. Need to look at profile and clean up inefficiencies in ZhangWangThin. I am reworking DirExpansion (old code moved to OldDir... function just in case) to act either on just ends of lines or both ends and isolated points, and based on the direction matrix follow from the point in a chain until it meets another valid point. Have now discovered the potential problem of loops, which have occured. IDK about them. 
26/05/2016 Comments/Thought guide on DirExpansion
%Feed index of valid start points into ImDir to acquire dirs per index
%value. The dirs matrix plus the raw index matrix plus M,N return a new
%they already exist. The remaining points plus the original points get
%moved to a new matrix. Evaluating the new ends (no iso points left), get
%new ends from those ends till it hits something. Keep evolving it. Need an
%algorithim implementing this to remove iso points. Keep a matrix of points
%to check and full evolved matrix.
DirExpansion seems to work on some parts of the pic. I tested it on a section that was effectively a flat line, that worked well. Other places, diagnals I know, something is buggy. There haven't been any chains going ad infinitum, as I expected. I wonder why. It is too late today for more work. 
27/05/2016 I haven't been working on this continually, but I want to finish it. I have been confused on how to best expand/thin/connect lines/isopoints in the image to make the line acquisition the easiest. I profiled ZhangWangThin, optimization for it is not effectively feasible/cost effective. The key places that delay, the only parts worth optimizing are 1) in the image to cols by sliding 4x4, I included the raw code for it, optimized to exactly barebones what I need, but the critical line in there is the "out= Mag( reshape( bsxfun( ..." trio of functions, and I don't think I can optimize those, 2) for loops for itterative section, much time in if statements, shouldn't matter for the choice application. All alt ways to do the interior of loops took longer, noted in class. This is my working strategy for expanding and thinning. 
1) Rapidly skeletonize with nonitterative ZhangWangThin, which should leave breaks in chains of a pixel or two. 
2) Repeat for a few itterations of 8-connectivity expansion followed by itterative ZhangWang. This should take care of 2 px gaps, but for each additional 2 desired, expansion must be executed an additional time before thinning, which creates spurs. Also, realized, spurs on this level are merely just ends of lines; at a higher level they are the ends of short lines attached to a larger established line. At a low level, I can only recede ends to eliminate spurs. I would have to get into line definitions in order to more choicely eliminate. 
Just doing 1&2, with 5 itterations of 2, where the number of itterations of expansion is also equal to the current itteration number, is over 10 min. with profiler. I ran it like so w/o profiler, took 540 seconds. Most of that was ZhangWangThin itterative, barely any (except the first round for some reason) was expansion, each call of that was >1 sec. The final image, I saved the mat file as spuriousFullyConnected..., is actually fully connected. Five rounds of expansion plus itterative thinning managed to connect everything, albiet produced a ton of spurs. The spurs are so bad they almost destroy the image; however, this discovery means something new now. I have two options, one I was planning before I realized this (quicker too I think) and the other is to proceed with this image, keep assumptionn of utter connectedness (I think it valid). 
3A) Lessen itterations to 2 or 3, find out which is better at minimizing spurs and time while acquiring connections. 
4A) Using a combo of DirExpansion (uses ImDir to find connections/points) and EndConnections (also uses ends, but makes no assumptions on direction, assumes proximity) finish connecting up lines. 
5A) Thin last time and remove spurs and isolated points. Everything now should be simply connected, except for loops of lines. 
6A) Acquire lines. If there is a junction, send a tracer down each, one will run into another, thus becoming a 'spur' somehow. 
3B) Using the full 5 itterations matrix, kill spurs and iso points harshly. Remove all points with neighbors of one or none many times. 
4B) Acquire lines. 
A requires more steps, but should be faster than B because B is more blunt and has to utilize the itterative thinning repeatedly on thick lines. 
I will begin by trying B, since I have already computed the starting matrix, and it should go smoothly. A would be quicker tho, personally want to develop down that line but I ought to just finish this. 
30/05/2016
Using a combination of spur/end/isopoint removing in loops with thinning, the image reduces to loops, endpoints of loops, and the huge overarching image of the hand. The loops are throwing me a bit, as false data caused by the expansion. I must refine that part, I do not like the sheer quantity and size of the loops. 
I stumbled onto some optimization strategies. When I was originally optimizing itterative ZhangWangThin, if statements to assign values is much more efficient than including the boolean evaluation operation in the assignment, eg toDelete( m + 1 + n*M ) = toDelete(...) && ~toDelete(m,n); However, using one for loop, running through the index rather than m,n is much more efficient. I reduced the 'optimized' 2 loop 3 if statement code to 1 loop 1 if statement, and that cut the time from 150sec to 50sec. With this, I am much more confident in putting in a bit more work into the expansion part, albeit I must finish. 
Working straight on line part. I have an idea. I'm stopping thinking about the itching expansion thing-ama-bobber because as I've been looking into how to do this line acquisition part, I think I have a way to make loops irrelevant. 1) Get simple lines, edges, lines that lie inbetween a critical point: end or split (3 connections). 2) Get critical points. 3) Associate edges with pairs of critical points: crit1, crit2, line4 (length/weight X). 3.5) If a line has both ends at the same end point, a loop, delete line, label split as end. 4) Run through splits. Ok: crit0, crit1, line1; find crit0->line2->crit2. 5) If crit2 is crit1, delete the longer line of 1 and 2, mark crit1/2 as not crit points, make new line crit-1, crit3, line(lastLine+1) (weight (line1)+line(2)+2). 6) If crit2 is not crit1, using the table of crit points make a list of trails between the points. 7) Make a new line composed of the intermediatory lines with the crit1/2 end points, keep/add to list the shortest line. This should converge to lines with ends, without loops, as short as possible. There might be, however, a problem if there is a quadrilateral. Will work on that then. I would also assume to delete lines with ends that are below a given threshold. 
